---
layout: post
title: "面试准备"
description: ""
category: ""
tags: []
---
{% include JB/setup %}

> *注：下面的内容是用来复习的，不是用来预习的。*

## 基本数据结构

### 栈

栈实现了一种后进先出（LIFO）的策略。如果试图对一个空栈作弹出操作，则称栈下溢；如果压栈操作超出了栈说能容纳的上限，则称栈上溢。

    push(S, x) {
        top[S] = top[S] + 1
        S[top[S]] = x
    }

    pop(S) {
        top[X] = top[S] - 1
        return S[top[S] + 1]
    }

### 队列

队列实现了一种先进先出（FIFO）的策略。当一个元素入队时，将排在队尾；出队的元素总是队首的元素。

    enqueue(Q, x) {
        Q[tail[Q]] = x
        if (tail[Q] == length[Q])
            tail[Q] = 1
        else
            tail[Q] = tail[Q] + 1
    }

    dequeue(Q) {
        x = Q[head[Q]]
        if head[Q] = length[Q]
            head[Q] = 1
        else
            head[Q] = head[Q] + 1
    }

### 链表

双链表的每一个元素都是一个对象。每个对象包含一个关键字和两个指针域：next和prev（分别指向下一个对象和上一个对象）。空对象可以用哨兵(sentinel)来表示，这样就简化了边界条件。

    list_delete(L, x) {
        // 不考虑边界条件时
        next[prev[x]] = nex[x]
        prev[next[x]] = prev[x]
    }

### 二叉查找树

即可用作字典，也可用作优先队列。

二叉查找树，或者是一棵空树，或者是具有下列性质的二叉树：对于树中的每个节点X，它的左子树中所有关键字的值都小于X的关键字值，而它的右子树中的所有关键字值都大于X的关键字的值。

在二叉查找树(binary search tree)上执行的基本操作的时间与树的高度成正比。一颗随机构造的二叉查找树的期望高度为O(lg n)。

如果x是一颗包含n个结点的子树的根，则中序遍历所有结点的时间为O(n)。

#### 查找后继

查找后继为找出在中序遍历下结点的后继。即某一结点x的后继为所有打渔key[x]中的最小的那个。分为两种情况。

*如果x的右子树非空，则x的后继即右子树中的最左结点；
*如果x的右子树为空，则x有一个后继y，y是x的最低祖先结点，且y的左儿子也是x的祖先。为找到y，可以从x开始向上查找，直到遇到某个是其父节点的左儿子的结点时为止。

#### 插入结点

该结点插入后是叶子结点。

#### 删除结点

将给定结点x删除，分三种情况：

* 如果x为叶子结点，直接删除，修改父节点的子女指针；
* 如果x只有一个子女，则可以通过在其子节点与父节点间建立一条链来删除x；
* 如果x有两个子女，则找到x的中序后继y（右子树的最左边的叶子结点），将y放在x所在的位置，删除y原来的结点。

查找、插入和删除的运行时间为O(h)，h为树的高度。

### 红黑树

红黑树是一种二叉查找树，通过对任何一条从根到叶子的路径上各个结点着色方式的限制，红黑树确保没有一条路径会比其他路径长两倍，因为是接近平衡的。

红黑树的性质：

1. 每个结点或是红的，或是黑的。
2. 根结点时黑的。
3. 每个叶节点（NIL）是黑的。
4. 如果一个结点时红的，则它的两个儿子都是黑的。
5. 对每个结点，从该结点到其子孙结点的所有路径上包含相同数目的黑结点。

在含n个关键字的红黑树上执行插入和删除结点操作的时间为O(lg n)。由于这两个操作对树作了修改，结果可能违反了红黑树的性质。为了保持红黑树性质，就要改变树中某些结点的颜色以及指针就够。

指针结构的修改是通过执行旋转来完成的。

### B树

B树是为磁盘或其他直接存取辅助存储设备而设计的一种平衡查找树。

一颗B树T是具有如下性质的有根数（根为root[T]）

1. 每个结点x有一下域：
    * n[x],当前存储在结点x中的关键字数
    * n[x]个关键字本身，以非降序存放，因此key1[x] <= key2[x] <= ... 
    * leaf[x]，是一个布尔值，如果x是叶子结点的话，则为true，否则为false。
2. 每个内结点x还包含n[x]+1个指向其子女的指针c1[x], c2[x], .... 。叶结点没有子女，故它们的ci域无定义。
3. 各关键字key[x]对储存在各子树中的关键字范围加以分隔。
4. 每个叶节点具有相同的深度，即树的高度h。
5. 每一个结点能包含的关键字树有一个上界和下界。这些界可用一个称作B树的最小度数的固定整数t>=2来表示。

## 算法

### 排序算法

#### 排序算法的稳定性

1） 稳定的：如果存在多个具有相同排序码的记录，经过排序后，这些记录的相对次序仍然保持不变，则这种排序算法称为稳定的。插入排序、冒泡排序、归并排序、分配排序（桶式、基数）都是稳定的排序算法。

2）不稳定的：否则称为不稳定的。快速排序、堆排序、直接选择排序shell排序都是不稳定的排序算法。

#### 排序算法的选择

1）若n较小(如n≤50)，可采用直接插入或直接选择排序。
当记录规模较小时，直接插入排序较好；否则因为直接选择移动的记录数少于直接插人，应选直接选择排序为宜。

2）若文件初始状态基本有序(指正序)，则应选用直接插人、冒泡或随机的快速排序为宜。

3）若n较大，则应采用时间复杂度为O(nlgn)的排序方法：快速排序、堆排序或归并排序。快速排序是目前基于比较的内部排序中被认为是最好的方法，当待排序的关键字是随机分布时，快速排序的平均时间最短；堆排序所需的辅助空间少于快速排序，并且不会出现快速排序可能出现的最坏情况。这两种排序都是不稳定的。

若要求排序稳定，则可选用归并排序。但本章介绍的从单个记录起进行两两归并的排序算法并不值得提倡，通常可以将它和直接插入排序结合在一起使用。先利用直接插入排序求得较长的有序子文件，然后再两两归并之。因为直接插入排序是稳定 的，所以改进后的归并排序仍是稳定的。

#### 二分搜索代码

{% highlight c %}
int binary_search(int *arr, int length, int key)
{
    int left, mid, right;

    left = 0;
    right = length - 1;
    mid = (left + right) / 2;

    while (left <= right) {
        if (arr[mid] == key)
            return mid;
        else if (arr[mid] < key)
            left = mid + 1;
        else
            right = mid - 1;

        mid = (left + right) / 2;
    }

    return -1;
}
{% endhighlight %}

#### 快排代码

{% highlight c %}
void qsort(int *arr, int left, int right)
{
    int i = left, j = right;
    int index = (left + right) / 2;
    int key = arr[index];

    while(i < j) {
        while ( arr[i] <= key && i < index) i++;
        if (i < index) {
            arr[index] = arr[i];
            index = i;
        }   

        while ( arr[j] >= key && j > index) j--;
        if (j > index) {
            arr[index] = arr[j];
            index = j;
        }   
    }
    
    arr[i] = key;

    if (left < i - 1)
        qsort(arr, left, i - 1);
    if (i + 1 < right)
        qsort(arr, i + 1, right);
}
{% endhighlight %}

<!--more-->

#### 堆排序代码

{% highlight c %}
#include <stdio.h>

#define PARENT(i) ((i) >> 1)
#define LEFT(i) ((i) << 1)
#define RIGHT(i) (((i) << 1) + 1)

void max_heapify(int *arr, int i, int heap_size)
{
    int largest = i;
    int left = LEFT(i);
    int right = RIGHT(i);
    int tmp;

    if (left <= heap_size && arr[left] > arr[largest]) {
        largest = left;
    }

    if (right <= heap_size && arr[right] > arr[largest]) {
        largest = right;
    }

    if (largest != i) {
        tmp = arr[largest];
        arr[largest] = arr[i];
        arr[i] = tmp;
        max_heapify(arr, largest, heap_size);
    }
}

void build_max_heap(int *arr, int heap_size)
{
    int i = PARENT(heap_size);

    for (; i >= 1; i--) {
        max_heapify(arr, i, heap_size);
    }
}

void heapsort(int *arr, int heap_size)
{
    int i, tmp;
    build_max_heap(arr, heap_size);

    for (i = heap_size; i >= 2; i--) {
        tmp = arr[1];
        arr[1] = arr[i];
        arr[i] = tmp;
        heap_size--;
        max_heapify(arr, 1, heap_size);
    }

}

void test_heapsort()
{
    int i;
    int arr[] = { 0, 16, 4, 10, 14, 7, 9, 3, 2, 8, 1 };
    heapsort(arr, 10);

    for (i = 1; i <= 10; i++){
        printf("%d ", arr[i]);
    }
    printf("\n");
    getchar();
}
{% endhighlight %}

### 动态规划

[动态规划：从新手到专家](http://hawstein.com/posts/dp-novice-to-advanced.html)

作者：Hawstein

出处：[http://hawstein.com/posts/dp-novice-to-advanced.html](http://hawstein.com/posts/dp-novice-to-advanced.html)

声明：本文采用以下协议进行授权： 自由转载-非商用-非衍生-保持署名|Creative Commons BY-NC-ND 3.0 ，转载请注明作者及出处。

#### 前言

本文翻译自TopCoder上的一篇文章：
[Dynamic Programming: From novice to advanced](http://community.topcoder.com/tc?module=Static&d1=tutorials&d2=dynProg)
，并非严格逐字逐句翻译，其中加入了自己的一些理解。水平有限，还望指摘。

#### 前言_

我们遇到的问题中，有很大一部分可以用动态规划(简称DP)来解。
解决这类问题可以很大地提升你的能力与技巧，我会试着帮助你理解如何使用DP来解题。
这篇文章是基于实例展开来讲的，因为干巴巴的理论实在不好理解。

注意：如果你对于其中某一节已经了解并且不想阅读它，没关系，直接跳过它即可。

#### 简介(入门)

**什么是动态规划，我们要如何描述它?**

动态规划算法通常基于一个递推公式及一个或多个初始状态。
当前子问题的解将由上一次子问题的解推出。使用动态规划来解题只需要多项式时间复杂度，
因此它比回溯法、暴力法等要快许多。

现在让我们通过一个例子来了解一下DP的基本原理。

首先，我们要找到某个状态的最优解，然后在它的帮助下，找到下一个状态的最优解。

**“状态”代表什么及如何找到它?**

"状态"用来描述该问题的子问题的解。原文中有两段作者阐述得不太清楚，跳过直接上例子。

如果我们有面值为1元、3元和5元的硬币若干枚，如何用最少的硬币凑够11元？
(表面上这道题可以用贪心算法，但贪心算法无法保证可以求出解，比如1元换成2元的时候)

首先我们思考一个问题，如何用最少的硬币凑够i元(i<11)？为什么要这么问呢？
两个原因：1.当我们遇到一个大问题时，总是习惯把问题的规模变小，这样便于分析讨论。
2.这个规模变小后的问题和原来的问题是同质的，除了规模变小，其它的都是一样的，
本质上它还是同一个问题(规模变小后的问题其实是原问题的子问题)。

好了，让我们从最小的i开始吧。当i=0，即我们需要多少个硬币来凑够0元。
由于1，3，5都大于0，即没有比0小的币值，因此凑够0元我们最少需要0个硬币。
(这个分析很傻是不是？别着急，这个思路有利于我们理清动态规划究竟在做些什么。)
这时候我们发现用一个标记来表示这句“凑够0元我们最少需要0个硬币。”会比较方便，
如果一直用纯文字来表述，不出一会儿你就会觉得很绕了。那么，
我们用d(i)=j来表示凑够i元最少需要j个硬币。于是我们已经得到了d(0)=0，
表示凑够0元最小需要0个硬币。当i=1时，只有面值为1元的硬币可用，
因此我们拿起一个面值为1的硬币，接下来只需要凑够0元即可，而这个是已经知道答案的，
即d(0)=0。所以，d(1)=d(1-1)+1=d(0)+1=0+1=1。当i=2时，
仍然只有面值为1的硬币可用，于是我拿起一个面值为1的硬币，
接下来我只需要再凑够2-1=1元即可(记得要用最小的硬币数量)，而这个答案也已经知道了。
所以d(2)=d(2-1)+1=d(1)+1=1+1=2。一直到这里，你都可能会觉得，好无聊，
感觉像做小学生的题目似的。因为我们一直都只能操作面值为1的硬币！耐心点，
让我们看看i=3时的情况。当i=3时，我们能用的硬币就有两种了：1元的和3元的(
5元的仍然没用，因为你需要凑的数目是3元！5元太多了亲)。
既然能用的硬币有两种，我就有两种方案。如果我拿了一个1元的硬币，我的目标就变为了：
凑够3-1=2元需要的最少硬币数量。即d(3)=d(3-1)+1=d(2)+1=2+1=3。
这个方案说的是，我拿3个1元的硬币；第二种方案是我拿起一个3元的硬币，
我的目标就变成：凑够3-3=0元需要的最少硬币数量。即d(3)=d(3-3)+1=d(0)+1=0+1=1.
这个方案说的是，我拿1个3元的硬币。好了，这两种方案哪种更优呢？
记得我们可是要用最少的硬币数量来凑够3元的。所以，
选择d(3)=1，怎么来的呢？具体是这样得到的：d(3)=min{d(3-1)+1, d(3-3)+1}。

OK，码了这么多字讲具体的东西，让我们来点抽象的。从以上的文字中，
我们要抽出动态规划里非常重要的两个概念：状态和状态转移方程。

上文中d(i)表示凑够i元需要的最少硬币数量，我们将它定义为该问题的"状态"，
这个状态是怎么找出来的呢？我在另一篇文章
[动态规划之背包问题(一)](/posts/dp-knapsack.html)中写过：
根据子问题定义状态。你找到子问题，状态也就浮出水面了。
最终我们要求解的问题，可以用这个状态来表示：d(11)，即凑够11元最少需要多少个硬币。
那状态转移方程是什么呢？既然我们用d(i)表示状态，那么状态转移方程自然包含d(i)，
上文中包含状态d(i)的方程是：d(3)=min{d(3-1)+1, d(3-3)+1}。没错，
它就是状态转移方程，描述状态之间是如何转移的。当然，我们要对它抽象一下，

d(i)=min{ d(i-v<sub>j</sub>)+1 }，其中i-v<sub>j</sub> >=0，v<sub>j</sub>表示第j个硬币的面值;

有了状态和状态转移方程，这个问题基本上也就解决了。当然了，Talk is cheap,show me 
the code!

伪代码如下：

<img src="/assets/img/2013/3/26/pseudocode.png" />

下图是当i从0到11时的解：

<img src="/assets/img/2013/3/26/sum.png" />

从上图可以得出，要凑够11元至少需要3枚硬币。

此外，通过追踪我们是如何从前一个状态值得到当前状态值的，
可以找到每一次我们用的是什么面值的硬币。比如，从上面的图我们可以看出，
最终结果d(11)=d(10)+1(面值为1)，而d(10)=d(5)+1(面值为5)，最后d(5)=d(0)+1
(面值为5)。所以我们凑够11元最少需要的3枚硬币是：1元、5元、5元。

注意：原文中这里本来还有一段的，但我反反复复读了几遍，
大概的意思我已经在上文从i=0到i=3的分析中有所体现了。作者本来想讲的通俗一些，
结果没写好，反而更不好懂，所以这段不翻译了。

#### 初级

上面讨论了一个非常简单的例子。现在让我们来看看对于更复杂的问题，
如何找到状态之间的转移方式(即找到状态转移方程)。
为此我们要引入一个新词叫递推关系来将状态联系起来(说的还是状态转移方程)

OK，上例子，看看它是如何工作的。

一个序列有N个数：A[1],A[2],...,A[N]，求出最长非降子序列的长度。
(讲DP基本都会讲到的一个问题LIS：longest increasing subsequence)

正如上面我们讲的，面对这样一个问题，我们首先要定义一个“状态”来代表它的子问题，
并且找到它的解。注意，大部分情况下，某个状态只与它前面出现的状态有关，
而独立于后面的状态。

让我们沿用“入门”一节里那道简单题的思路来一步步找到“状态”和“状态转移方程”。
假如我们考虑求A[1],A[2],...,A[i]的最长非降子序列的长度，其中i<N，
那么上面的问题变成了原问题的一个子问题(问题规模变小了，你可以让i=1,2,3等来分析)
然后我们定义d(i)，表示前i个数中以A[i]结尾的最长非降子序列的长度。OK，
对照“入门”中的简单题，你应该可以估计到这个d(i)就是我们要找的状态。
如果我们把d(1)到d(N)都计算出来，那么最终我们要找的答案就是这里面最大的那个。
状态找到了，下一步找出状态转移方程。

为了方便理解我们是如何找到状态转移方程的，我先把下面的例子提到前面来讲。
如果我们要求的这N个数的序列是：

    5，3，4，8，6，7

根据上面找到的状态，我们可以得到：（下文的最长非降子序列都用LIS表示）

* 前1个数的LIS长度d(1)=1(序列：5)
* 前2个数的LIS长度d(2)=1(序列：3；3前面没有比3小的)
* 前3个数的LIS长度d(3)=2(序列：3，4；4前面有个比它小的3，所以d(3)=d(2)+1)
* 前4个数的LIS长度d(4)=3(序列：3，4，8；8前面比它小的有3个数，所以
  d(4)=max{d(1),d(2),d(3)}+1=3)

OK，分析到这，我觉得状态转移方程已经很明显了，如果我们已经求出了d(1)到d(i-1)，
那么d(i)可以用下面的状态转移方程得到：

    d(i) = max{1, d(j)+1},其中j<i,A[j]<=A[i]
    
用大白话解释就是，想要求d(i)，就把i前面的各个子序列中，
最后一个数不大于A[i]的序列长度加1，然后取出最大的长度即为d(i)。
当然了，有可能i前面的各个子序列中最后一个数都大于A[i]，那么d(i)=1，
即它自身成为一个长度为1的子序列。

分析完了，上图：(第二列表示前i个数中LIS的长度，
第三列表示，LIS中到达当前这个数的上一个数的下标，根据这个可以求出LIS序列)

<img src="/assets/img/2013/3/26/lis.png" />

Talk is cheap, show me the code:

{% highlight cpp %}
#include <iostream>
using namespace std;

int lis(int A[], int n){
    int *d = new int[n];
    int len = 1;
    for(int i=0; i<n; ++i){
        d[i] = 1;
        for(int j=0; j<i; ++j)
            if(A[j]<=A[i] && d[j]+1>d[i])
                d[i] = d[j] + 1;
        if(d[i]>len) len = d[i];
    }
    delete[] d;
    return len;
}
int main(){
    int A[] = {
        5, 3, 4, 8, 6, 7
    };
    cout<<lis(A, 6)<<endl;
    return 0;
}
{% endhighlight %}

该算法的时间复杂度是O(n^2 )，并不是最优的解法。
还有一种很巧妙的算法可以将时间复杂度降到O(nlogn)，网上已经有各种文章介绍它，
这里就不再赘述。传送门：
[LIS的O(nlogn)解法](http://www.felix021.com/blog/read.php?1587)。
此题还可以用“排序+LCS”来解，感兴趣的话可自行Google。

**练习题**

无向图G有N个结点(1<N<=1000)及一些边，每一条边上带有正的权重值。
找到结点1到结点N的最短路径，或者输出不存在这样的路径。

提示：在每一步中，对于那些没有计算过的结点，
及那些已经计算出从结点1到它的最短路径的结点，如果它们间有边，
则计算从结点1到未计算结点的最短路径。

尝试解决以下来自topcoder竞赛的问题：

* [ZigZag](http://community.topcoder.com/tc?module=ProblemDetail&rd=4493&pm=1259) - 2003 TCCC Semifinals 3
* [BadNeighbors](http://community.topcoder.com/tc?module=ProblemDetail&rd=5009&pm=2402) - 2004 TCCC Round 4
* [FlowerGarden](http://community.topcoder.com/tc?module=ProblemDetail&rd=5006&pm=1918) - 2004 TCCC Round 1

#### 中级

接下来，让我们来看看如何解决二维的DP问题。

平面上有N*M个格子，每个格子中放着一定数量的苹果。你从左上角的格子开始，
每一步只能向下走或是向右走，每次走到一个格子上就把格子里的苹果收集起来，
这样下去，你最多能收集到多少个苹果。

解这个问题与解其它的DP问题几乎没有什么两样。第一步找到问题的“状态”，
第二步找到“状态转移方程”，然后基本上问题就解决了。

首先，我们要找到这个问题中的“状态”是什么？我们必须注意到的一点是，
到达一个格子的方式最多只有两种：从左边来的(除了第一列)和从上边来的(除了第一行)。
因此为了求出到达当前格子后最多能收集到多少个苹果，
我们就要先去考察那些能到达当前这个格子的格子，到达它们最多能收集到多少个苹果。
(是不是有点绕，但这句话的本质其实是DP的关键：欲求问题的解，先要去求子问题的解)

经过上面的分析，很容易可以得出问题的状态和状态转移方程。
状态S[i][j]表示我们走到(i, j)这个格子时，最多能收集到多少个苹果。那么，
状态转移方程如下：

    S[i][j]=A[i][j] + max(S[i-1][j], if i>0 ; S[i][j-1], if j>0)
    
其中i代表行，j代表列，下标均从0开始；A[i][j]代表格子(i, j)处的苹果数量。

S[i][j]有两种计算方式：1.对于每一行，从左向右计算，然后从上到下逐行处理；2.
对于每一列，从上到下计算，然后从左向右逐列处理。
这样做的目的是为了在计算S[i][j]时，S[i-1][j]和S[i][j-1]都已经计算出来了。

伪代码如下：

<img src="/assets/img/2013/3/26/2d-dp.png" />

以下两道题来自topcoder，练习用的。

* [AvoidRoads](http://community.topcoder.com/tc?module=ProblemDetail&rd=4709&pm=1889) - 2003 TCO Semifinals 4
* [ChessMetric](http://community.topcoder.com/tc?module=ProblemDetail&rd=4482&pm=1592) - 2003 TCCC Round 4

#### 中高级

这一节要讨论的是带有额外条件的DP问题。

以下的这个问题是个很好的例子。

无向图G有N个结点，它的边上带有正的权重值。

你从结点1开始走，并且一开始的时候你身上带有M元钱。如果你经过结点i，
那么你就要花掉S[i]元(可以把这想象为收过路费)。如果你没有足够的钱，
就不能从那个结点经过。在这样的限制条件下，找到从结点1到结点N的最短路径。
或者输出该路径不存在。如果存在多条最短路径，那么输出花钱数量最少的那条。
限制：1<N<=100 ; 0<=M<=100 ; 对于每个i，0<=S[i]<=100；正如我们所看到的，
如果没有额外的限制条件(在结点处要收费，费用不足还不给过)，那么，
这个问题就和经典的迪杰斯特拉问题一样了(找到两结点间的最短路径)。
在经典的迪杰斯特拉问题中，
我们使用一个一维数组来保存从开始结点到每个结点的最短路径的长度，
即M[i]表示从开始结点到结点i的最短路径的长度。然而在这个问题中，
我们还要保存我们身上剩余多少钱这个信息。因此，很自然的，
我们将一维数组扩展为二维数组。M[i][j]表示从开始结点到结点i的最短路径长度，
且剩余j元。通过这种方式，我们将这个问题规约到原始的路径寻找问题。
在每一步中，对于已经找到的最短路径，我们找到它所能到达的下一个未标记状态(i,j)，
将它标记为已访问(之后不再访问这个结点)，并且在能到达这个结点的各个最短路径中，
找到加上当前边权重值后最小值对应的路径，即为该结点的最短路径。
(写起来真是绕，建议画个图就会明了很多)。不断重复上面的步骤，
直到所有的结点都访问到为止(这里的访问并不是要求我们要经过它，
比如有个结点收费很高，你没有足够的钱去经过它，但你已经访问过它)
最后Min[N-1][j]中的最小值即是问题的答案(如果有多个最小值，
即有多条最短路径，那么选择j最大的那条路径，即，使你剩余钱数最多的最短路径)。

伪代码：

<img src="/assets/img/2013/3/26/shortest-path.png" />

下面有几道topcoder上的题以供练习：

* [Jewelry](http://community.topcoder.com/tc?module=ProblemDetail&rd=4705&pm=1166) - 2003 TCO Online Round 4
* [StripePainter](http://community.topcoder.com/tc?module=ProblemDetail&rd=4555&pm=1215) - SRM 150 Div 1
* [QuickSums](http://community.topcoder.com/tc?module=ProblemDetail&rd=5072&pm=2829) - SRM 197 Div 2
* [ShortPalindromes](http://community.topcoder.com/tc?module=ProblemDetail&rd=4630&pm=1861) - SRM 165 Div 2

#### 高级

以下问题需要仔细的揣摩才能将其规约为可用DP解的问题。

问题：[StarAdventure](http://community.topcoder.com/tc?module=ProblemDetail&rd=5854&pm=2940) - SRM 208 Div 1: 

给定一个M行N列的矩阵(M*N个格子)，每个格子中放着一定数量的苹果。
你从左上角的格子开始，只能向下或向右走，目的地是右下角的格子。
你每走过一个格子，就把格子上的苹果都收集起来。然后你从右下角走回左上角的格子，
每次只能向左或是向上走，同样的，走过一个格子就把里面的苹果都收集起来。
最后，你再一次从左上角走到右下角，每过一个格子同样要收集起里面的苹果
(如果格子里的苹果数为0，就不用收集)。求你最多能收集到多少苹果。

注意：当你经过一个格子时，你要一次性把格子里的苹果都拿走。

限制条件：1 < N, M <= 50；每个格子里的苹果数量是0到1000(包含0和1000)。

如果我们只需要从左上角的格子走到右下角的格子一次，并且收集最大数量的苹果，
那么问题就退化为“中级”一节里的那个问题。将这里的问题规约为“中级”里的简单题，
这样一来会比较好解。让我们来分析一下这个问题，要如何规约或是修改才能用上DP。
首先，对于第二次从右下角走到左上角得出的这条路径，
我们可以将它视为从左上角走到右下角得出的路径，没有任何的差别。
(即从B走到A的最优路径和从A走到B的最优路径是一样的)通过这种方式，
我们得到了三条从顶走到底的路径。对于这一点的理解可以稍微减小问题的难度。
于是，我们可以将这3条路径记为左，中，右路径。对于两条相交路径(如下图)：

<img src="/assets/img/2013/3/26/intersect.png" />

在不影响结果的情况下，我们可以将它们视为两条不相交的路径：

<img src="/assets/img/2013/3/26/no-intersect.png" />

这样一来，我们将得到左，中，右3条路径。此外，如果我们要得到最优解，
路径之间不能相交(除了左上角和右下角必然会相交的格子)。因此对于每一行y(
除了第一行和最后一行)，三条路径对应的x坐标要满足：x1[y] < x2[y] < x3[y]。
经过这一步的分析，问题的DP解法就进一步地清晰了。让我们考虑行y，
对于每一个x1[y-1]，x2[y-1]和x3[y-1]，我们已经找到了能收集到最多苹果数量的路径。
根据它们，我们能求出行y的最优解。现在我们要做的就是找到从一行移动到下一行的方式。
令Max[i][j][k]表示到第y-1行为止收集到苹果的最大数量，
其中3条路径分别止于第i,j,k列。对于下一行y，对每个Max[i][j][k]
都加上格子(y,i)，(y,j)和(y,k)内的苹果数量。因此，每一步我们都向下移动。
我们做了这一步移动之后，还要考虑到，一条路径是有可能向右移动的。
(对于每一个格子，我们有可能是从它上面向下移动到它，
也可能是从它左边向右移动到它)。为了保证3条路径互不相交，
我们首先要考虑左边的路径向右移动的情况，然后是中间，最后是右边的路径。
为了更好的理解，让我们来考虑左边的路径向右移动的情况，对于每一个可能的j,k对(j<k)，
对每个i(i<j)，考虑从位置(i-1,j,k)移动到位置(i,j,k)。处理完左边的路径，
再处理中间的路径，最后处理右边的路径。方法都差不多。

用于练习的topcoder题目：

* [MiniPaint](http://community.topcoder.com/tc?module=ProblemDetail&rd=4710&pm=1996) - SRM 178 Div 1

#### 其它

当阅读一个题目并且开始尝试解决它时，首先看一下它的限制。
如果要求在多项式时间内解决，那么该问题就很可能要用DP来解。遇到这种情况，
最重要的就是找到问题的“状态”和“状态转移方程”。(状态不是随便定义的，
一般定义完状态，你要找到当前状态是如何从前面的状态得到的，
即找到状态转移方程)如果看起来是个DP问题，但你却无法定义出状态，
那么试着将问题规约到一个已知的DP问题(正如“高级”一节中的例子一样)。

#### 后记

看完这教程离DP专家还差得远，好好coding才是王道。

## 操作系统

### 进程

#### 进程和线程的区别

进程是程序的一次执行。线程可以理解为进程中执行的一段程序片段。在一个多任务环境中下面的概念可以帮助我们理解两者间的差别。

进程间是独立的，这表现在内存空间、上下文环境上；线程运行在进程空间内。一般来讲，进程无法突破进程边界存取其他进程内的存储空间，而线程由于处于进程空间内，所以同一进程所产生的线程共享统一内存空间。

同一进程中的两段代码不能同时执行，除非引入线程。

线程是属于进程的，当进程退出时该进程所产生的线程都会被强制退出并清楚。线程占用的资源要少于进程所占用的资源。进程和线程都有优先级。

进程间可以通过IPC通信，但线程不可以。

### IPC

1. 管道（Pipe）及有名管道（named pipe）：管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；
2. 信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）；
3. 报文（Message）队列（消息队列）：消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。
5. 信号量（semaphore）：主要作为进程间以及同一进程不同线程之间的同步手段。
6. 套接口（Socket）：更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。

### Linux命令

#### netstat

netstat  -  Print network connections, routing tables, interface statistics, mas‐querade connections(伪连接), and multicast memberships.

-a (all)显示所有选项，默认不显示LISTEN相关
-t (tcp)仅显示tcp相关选项
-u (udp)仅显示udp相关选项
-n 拒绝显示别名，能显示数字的全部转化成数字。
-l 仅列出有在 Listen (监听) 的服務状态
-p 显示建立相关链接的程序名
-r 显示路由信息，路由表
-e 显示扩展信息，例如uid等
-s 按各个协议进行统计
-c 每隔一个固定时间，执行该netstat命令。

推荐命令：ss , ip

#### tcpdump

dump traffic on a network

tcpdump可以将网络中传送的数据包的“头”完全截获下来提供分析。

#### ipcs

ipcs - provide information on ipc facilities

ipc show 显示进程间通信的信息

#### ipcrm

ipcrm - remove a message queue, semaphore set or shared memory id

#### sed

[sed 简明教程](http://coolshell.cn/articles/9104.html)

#### awk

[awk 简明教程](http://coolshell.cn/articles/9070.html)

## 网络

### TCP

3次握手建立一个连接。

1. 第一次握手：建立连接时，客户端发送SYN包(SYN=j)到服务器，并进入SYN_SEND状态，等待服务器确认。
2. 第二次握手：服务器收到SYN包，必须确认客户的SYN（ACK=j+1）,同时自己也发送一个SYN包（SYN=k），即SYN+ACK包，此时服务器进入SYN_RECV状态。
3. 第三次握手：客户端收到服务器的SYN+ACK包，向服务器发送确认包ACK（ACK=k+1），此包发送完毕，客户端和服务器进入ESTABLISHED状态，完成3次握手。

4次挥手断开一个连接（假设由客户端主动关闭连接）。

1. 第一次挥手：客户端发送一个FIN包(FIN=j)到服务器，客户端进入FIN_WAIT_1状态。
2. 第二次挥手：服务器收到FIN包，确认客户的FIN（ACK=j+1）,服务器进入CLOSE_WAIT状态。
3. 第三次挥手：服务器发送一个FIN包(FIN=k)到客户端，服务器进入LAST_ACK状态。
4. 第四次挥手：客户端收到FIN包，客户端进入TIME_WIAT状态，确认服务器的FIN（ACK=k+1），服务器收到确认ACK后，服务器进入CLOSED状态，完成四次挥手。

### HTTP

## C/C++

### 静态函数

静态函数会被自动分配在一个一直使用的存储区，直到退出应用程序实例，避免了调用函数时压栈出栈，速度快很多。

关键字“static”，译成中文就是“静态的”，所以内部函数又称静态函数。但此处“static”的含义不是指存储方式，而是指对函数的作用域仅局限于本文件。 使用内部函数的好处是：不同的人编写不同的函数时，不用担心自己定义的函数，是否会与其它文件中的函数同名，因为同名也没有关系。

1、 静态函数与普通函数的区别在于：静态函数不可以被同一源文件以外的函数调用。

2、 静态局部变量与普通局部变量的区别在于：静态局部变量只初始化一次，下一次初始化实际上是依然是上一次的变量；

3、 静态全局变量与普通全局变量的区别在于：静态全局变量的作用域仅限于所在的源文件。